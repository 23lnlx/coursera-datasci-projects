{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'product-reviews-sentiment-analysis-light'\n",
    "TRAIN = 'products_sentiment_train.tsv'\n",
    "TEST = 'products_sentiment_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(PATH_TO_DATA, TRAIN), sep='\\t', header=None)\n",
    "df_train.columns = ['text', 'lab']\n",
    "df_test = pd.read_csv(os.path.join(PATH_TO_DATA, TEST), sep='\\t', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  lab\n",
       "0          2 . take around 10,000 640x480 pictures .    1\n",
       "1  i downloaded a trial version of computer assoc...    1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...    1\n",
       "3  i dont especially like how music files are uns...    0\n",
       "4  i was using the cheapie pail ... and it worked...    1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns = ['text', 'lab']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: lab, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.lab.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ой, у нас количество классов не равно. Давайте потратим время на выравнивание количества классов, как правило, это дает улучшение предсказания (для классификатора, веторизатор при этим портится). Также при равенстве классов нам хватит accuracy для оценки модели. Выравнивать будет случайным дублированием отрицательных отзывов.\n",
    "Оценивать будем по красс-валидации. При oversampling-e это не самый лучший вариант (так как могут получиться развиения, когда алгоритм видел отзыв заранее), поэтому найдем сначала \"работающий достаточно хорошо\" по необработанным данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train.text, df_train.lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_od_0s = X.index[y == 0]\n",
    "X_1, y_1 = X[y == 1], y[y == 1]\n",
    "index_oversample = np.random.choice(index_od_0s, size=df_train.lab.value_counts()[1])\n",
    "X_resampled = np.concatenate([X[index_oversample],X_1])\n",
    "y_resampled = np.concatenate([y[index_oversample],y_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape[0]/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот теперь лучше. Давайте теперь проверим все векторизаторы и классификаторы со стандартными параметрами, а потом проведем поиск по сетке у лучших. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: Count, Est: LR, \tacc: 0.8590952601513047\n",
      "Pre: Count, Est: SGD, \tacc: 0.8296788636714529\n",
      "Pre: Count, Est: SVM, \tacc: 0.8630230044773816\n",
      "Pre: TFIDF, Est: LR, \tacc: 0.8390721012814575\n",
      "Pre: TFIDF, Est: SGD, \tacc: 0.8618403581905204\n",
      "Pre: TFIDF, Est: SVM, \tacc: 0.8638042303535588\n",
      "Pre: Hash, Est: LR, \tacc: 0.7998270804384746\n",
      "Pre: Hash, Est: SGD, \tacc: 0.8394673459935156\n",
      "Pre: Hash, Est: SVM, \tacc: 0.8563439864134631\n"
     ]
    }
   ],
   "source": [
    "for name_pre, preproc in [('Count', CountVectorizer), ('TFIDF', TfidfVectorizer), ('Hash', HashingVectorizer)]:\n",
    "    for name_est, est in [('LR', LogisticRegression), ('SGD', SGDClassifier), ('SVM', LinearSVC)]:\n",
    "        pipe = Pipeline([\n",
    "            ('preproc', preproc()),\n",
    "            ('est', est())\n",
    "        ])\n",
    "        acc = cross_val_score(pipe, X_resampled, y=y_resampled, scoring='accuracy', cv=5).mean()\n",
    "        \n",
    "        print('Pre: {}, Est: {}, \\tacc: {}'.format(name_pre, name_est, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: Count, Est: LR, \tacc: 0.7684956843480272\n",
      "Pre: Count, Est: SGD, \tacc: 0.7334793373708586\n",
      "Pre: Count, Est: SVM, \tacc: 0.754000653129082\n",
      "Pre: TFIDF, Est: LR, \tacc: 0.7665031843949025\n",
      "Pre: TFIDF, Est: SGD, \tacc: 0.7524918686991794\n",
      "Pre: TFIDF, Est: SVM, \tacc: 0.7684856717854487\n",
      "Pre: Hash, Est: LR, \tacc: 0.7490006281289258\n",
      "Pre: Hash, Est: SGD, \tacc: 0.7564893936837105\n",
      "Pre: Hash, Est: SVM, \tacc: 0.7689881780511127\n"
     ]
    }
   ],
   "source": [
    "# без ресампла\n",
    "for name_pre, preproc in [('Count', CountVectorizer), ('TFIDF', TfidfVectorizer), ('Hash', HashingVectorizer)]:\n",
    "    for name_est, est in [('LR', LogisticRegression), ('SGD', SGDClassifier), ('SVM', LinearSVC)]:\n",
    "        pipe = Pipeline([\n",
    "            ('preproc', preproc()),\n",
    "            ('est', est())\n",
    "        ])\n",
    "        acc = cross_val_score(pipe, X, y=y, scoring='accuracy', cv=5).mean()\n",
    "        \n",
    "        print('Pre: {}, Est: {}, \\tacc: {}'.format(name_pre, name_est, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HashingVectorizer, не имея вообще никаких обосновний для работы, почему-то показывает очень неплохой результат. Но он сравним с другими, а его нестабильность не позволяет верить в то, что мы получим устойчивое решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте оставим SVM с TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "vec.fit(X)\n",
    "\n",
    "X_transformed = vec.transform(X)\n",
    "\n",
    "est = LinearSVC()\n",
    "est.fit(X_transformed, y)\n",
    "\n",
    "X_test = vec.transform(df_test.text)\n",
    "\n",
    "df_test['y'] = est.predict(X_test)\n",
    "df_test[['y']].to_csv('sub_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему-то стабилизация вариантов только ухудшила результат. Выше - вариант, который получился лучшем на LeaderBoard. Так как он уже бьет бенчмарк, то докручивать что-то мне лень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
